services:
  # Apache Spark Master
  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    hostname: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - "8080:8080"  # Spark Master UI
      - "7077:7077"  # Spark Master Port
      - "4040:4040"  # Spark Application UI
    volumes:
      - ./spark/apps:/opt/spark-apps
      - ./spark/data:/opt/spark-data
    networks:
      - aiops-network

  # Apache Spark Worker
  spark-worker:
    image: apache/spark:3.5.0
    container_name: spark-worker
    hostname: spark-worker
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_PORT=8881
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8081:8081"  # Spark Worker UI
    depends_on:
      - spark-master
    volumes:
      - ./spark/apps:/opt/spark-apps
      - ./spark/data:/opt/spark-data
    networks:
      - aiops-network

  # Elasticsearch for metrics and logs storage
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:9.0.0-beta1
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.http.ssl.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - aiops-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Kibana for visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:9.0.0-beta1
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - XPACK_SECURITY_ENABLED=false
    ports:
      - "5601:5601"
    volumes:
      - ./kibana/dashboards:/usr/share/kibana/dashboards
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - aiops-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # OpenTelemetry Collector - Agent Mode (Data Collection)
  otel-collector-agent:
    image: otel/opentelemetry-collector-contrib:0.115.1
    container_name: otel-collector-agent
    command: ["--config=/etc/otel-collector-agent-config.yaml"]
    volumes:
      - ./otel/otel-collector-agent-config.yaml:/etc/otel-collector-agent-config.yaml
      - ./otel/logs:/var/log/otel
    ports:
      - "4317:4317"   # OTLP gRPC receiver (keep original for external apps)
      - "4318:4318"   # OTLP HTTP receiver (keep original for external apps)
      - "13133:13133" # health_check extension
      - "8888:8888"   # metrics endpoint
    depends_on:
      - spark-master
    networks:
      - aiops-network

  # OpenTelemetry Collector - Gateway Mode (ETL & Batching)
  otel-collector-gateway:
    image: otel/opentelemetry-collector-contrib:0.115.1
    container_name: otel-collector-gateway
    command: ["--config=/etc/otel-collector-gateway-config.yaml"]
    volumes:
      - ./otel/otel-collector-gateway-config.yaml:/etc/otel-collector-gateway-config.yaml
    ports:
      - "4319:4317"   # OTLP gRPC receiver (different external port)
      - "4320:4318"   # OTLP HTTP receiver (different external port)
      - "13134:13133" # health_check extension (different external port)
      - "8889:8888"   # metrics endpoint (different external port)
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - aiops-network

  # Log Generator Service - Simulates continuous log generation
  log-generator:
    image: alpine:latest
    container_name: log-generator
    command: >
      sh -c "
        apk add --no-cache bash &&
        while true; do
          timestamp=$$(date -u +'%Y-%m-%dT%H:%M:%S.%3NZ');
          case $$(($$RANDOM % 8)) in
            0) echo \"$$timestamp INFO [spark-app] Processing batch $$(($$RANDOM % 10000 + 1000)) records\" >> /var/log/otel/application.log ;;
            1) echo \"$$timestamp DEBUG [spark-driver] Memory usage: $$(($$RANDOM % 100))%\" >> /var/log/otel/application.log ;;
            2) echo \"$$timestamp WARN [spark-executor] Task execution time exceeded: $$(($$RANDOM % 5000 + 1000))ms\" >> /var/log/otel/application.log ;;
            3) echo \"$$timestamp INFO [anomaly-detector] Found $$(($$RANDOM % 20)) anomalies\" >> /var/log/otel/application.log ;;
            4) echo \"$$timestamp DEBUG [data-pipeline] Cache hits: $$(($$RANDOM % 1000))\" >> /var/log/otel/application.log ;;
            5) echo \"$$timestamp ERROR [spark-sql] Query timeout after $$(($$RANDOM % 30 + 10)) seconds\" >> /var/log/otel/application.log ;;
            6) if [ $$(($$RANDOM % 10)) -eq 0 ]; then 
                 echo \"$$timestamp ERROR [system] This is a very long error message that should be truncated by the ETL processor when it exceeds the 10000 character limit. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium.\" >> /var/log/otel/application.log;
               else 
                 echo \"$$timestamp INFO [system] Health check passed\" >> /var/log/otel/application.log;
               fi ;;
            7) echo \"$$timestamp DEBUG [monitoring] Metrics collection completed\" >> /var/log/otel/application.log ;;
          esac;
          sleep $$(($$RANDOM % 15 + 10));
        done
      "
    volumes:
      - ./otel/logs:/var/log/otel
    networks:
      - aiops-network

networks:
  aiops-network:
    driver: bridge

volumes:
  elasticsearch-data:
